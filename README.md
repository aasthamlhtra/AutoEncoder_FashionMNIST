#  Deep Autoencoder for FashionMNIST Image Reconstruction

This project demonstrates the construction, training, and evaluation of a **deep fully connected autoencoder** using PyTorch. The autoencoder is trained on the **FashionMNIST** dataset to learn efficient low-dimensional representations of grayscale fashion images and reconstruct them from these representations.

---

##  What is an Autoencoder?

An **autoencoder** is a type of neural network used for **unsupervised learning**, primarily for **dimensionality reduction**, **denoising**, or **image compression**. It works by encoding the input into a lower-dimensional space and then decoding it back to reconstruct the original input.

---

###  Features

- Loads FashionMNIST dataset using `torchvision.datasets`
- Defines a **deep symmetric autoencoder** with 5 encoding and 5 decoding layers
- Uses **MSELoss** as the reconstruction criterion
- Trains the model using the **Adam** optimizer
- Saves output reconstructions every 5 epochs during training
- Produces a final comparison image and training loss plot

---

## Model Architecture

### Encoder (input: 784 = 28Ã—28 image):
- `Linear(784 â†’ 256)` â†’ ReLU
- `Linear(256 â†’ 128)` â†’ ReLU
- `Linear(128 â†’ 64)` â†’ ReLU
- `Linear(64 â†’ 32)` â†’ ReLU
- `Linear(32 â†’ 16)` â†’ ReLU

### Decoder (mirror of encoder):
- `Linear(16 â†’ 32)` â†’ ReLU
- `Linear(32 â†’ 64)` â†’ ReLU
- `Linear(64 â†’ 128)` â†’ ReLU
- `Linear(128 â†’ 256)` â†’ ReLU
- `Linear(256 â†’ 784)` â†’ ReLU


---

## ğŸ› ï¸ Setup & Dependencies

Install dependencies:

```bash
pip install torch torchvision matplotlib
